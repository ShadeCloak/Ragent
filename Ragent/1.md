
deepseek_llm = DeepseekLM(
    api_url="https://api.deepseek.com/v1",
    api_token="sk-cdd4c6ddedbb45e8b9bb8a6fc36a0145",
    model_name="deepseek-chat",
    meta_template=INTERNLM2_META,
    stop_words=['<|im_end|>']
)

env = Env([WebSearch(), CodeExecutor()])

plugin_executor = ActionExecutor(BingBrowser(searcher_type='DuckDuckGoSearch', topk=3))

# 初始化 Internlm2Agent 实例
agent = Internlm2Agent(
    llm=deepseek_llm,
    plugin_executor=ActionExecutor(
        BingBrowser(searcher_type='DuckDuckGoSearch', topk=6)
    ),
    protocol=Internlm2Protocol(
        meta_prompt=META_CN,
        plugin_prompt=PLUGIN_CN, 
        tool=dict( 
            begin='{start_token}{name}\n', 
            start_token='<|action_start|>', 
            name_map=dict(plugin='<|plugin|>', interpreter='<|interpreter|>'),
            belong='assistant',
            end='<|action_end|>\n',
        ),
    ),
)

# 创建环境实例
env = Env([WebSearch(), CodeExecutor()])

# 创建 LLM 实例
llm = DoubaoAPI(
    mode='psm',
    psm_cfg=dict(
        model_name=model_name,
        psm='data.seed.rl_human_eval',
        idc='lq',
        llm_cluster=model_name,
    )
)

# 创建协议实例
protocol = DoubaoProtocol()

# 创建 ReAct 代理实例
agent = ReAct(
    llm=llm,
    env=env,
    protocol=protocol
)

# 运行代理实例并传入用户问题
response = agent.run("阿里巴巴在 2023 年的电商业务交易额是多少？同时对比一下京东在同年的电商业务交易额，然后评估一下两家企业在电商领域的核心竞争力分别是什么")

print(response)




def run(self, inputs: Optional[str] = None) -> str:
    """
    Run the ReAct agent in an interactive loop.
    
    Args:
        inputs (Optional[str]): The user input to start the conversation.
    
    Returns:
        str: Final response after completing the interaction.
    """
    # 将用户输入添加到对话状态中
    self.state.add(role='user', content=inputs)

    for turn in range(self.max_turn):
        # 从语言模型中获取响应
        llm_response = self.llm.chat(self.state.history)
        print(colored(f"Assistant: {llm_response}", 'blue'))

        # 将 LLM 响应添加到对话状态中
        self.state.add(role='assistant', content=llm_response)

        # 解析 LLM 响应，确定是否需要执行某个操作
        message, action = self.protocol.parse(llm_response)

        # 如果不需要执行操作，假设对话已结束并返回最终消息
        if action is None:
            return message

        # 在环境中执行操作并捕获响应
        try:
            env_response = self.env(**action)
        except Exception as e:
            env_response = f"Error during environment interaction: {str(e)}"

        print(colored(f"Environment: {env_response}", 'green'))

        # 将环境响应添加到对话状态中
        self.state.add(role='tool', content=env_response)

    # 如果达到最大轮数且没有结束状态，返回此消息
    return "Not finished"